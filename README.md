# ğŸ•¸ï¸ Web Scraper

This Python-based project uses **BeautifulSoup** ğŸ¥£ and **Pandas** ğŸ¼ to scrape HTML tables from a given webpage ğŸŒ and save the data into a CSV file ğŸ“‚. It includes a user-friendly terminal-based loading animation â³ to enhance the experience during the scraping process.

---

## âœ¨ Features
- ğŸŒ **Web Scraping**: Extracts HTML tables from the provided URL.
- ğŸ“ **CSV Export**: Saves the extracted data into a dynamically named CSV file.
- ğŸ›¡ï¸ **Error Handling**: Gracefully handles missing data, invalid URLs, and empty tables.
- ğŸ¡ **Loading Animation**: Displays a fun spinner during the scraping process.
- ğŸ”– **Dynamic Column Names**: Automatically generates column headers if not present in the table.

---

## ğŸ“¦ Requirements
### ğŸ› ï¸ Dependencies
Ensure you have Python 3.6+ installed, and install the required libraries:

```bash
pip install -r requirements.txt
```

Your `requirements.txt` should include:

```plaintext
beautifulsoup4==4.12.2
pandas==1.5.3
requests==2.31.0
```

---

## ğŸš€ How to Use
1. **Clone the repository**:

   ```bash
   git clone https://github.com/arktrek/web-scraper.git
   cd web-scraper
   ```

2. **Run the script**:

   ```bash
   python main.py
   ```

3. **Input the URL**:  
   Enter the URL of a webpage containing an HTML table (e.g., [W3Schools Tables](https://www.w3schools.com/html/html_tables.asp)) when prompted:

   ```plaintext
   Enter the URL of the webpage to scrape: https://www.w3schools.com/html/html_tables.asp
   ```

4. **Results**:  
   - Data is saved into a CSV file with a timestamped name like `scraped_data_YYYYMMDD_HHMMSS.csv`.  
   - Look for the file in the current directory ğŸ“‚.

---

## ğŸ§¾ Example Output
Hereâ€™s an example of how the scraped data may look:

| ğŸ§‘ Name       | ğŸŒ Country   | ğŸ”¢ Age  |
|---------------|-------------|---------|
| ABCD          | INDIA       | 25      |
| abcd          | USA         | 30      |

The above table is saved as `scraped_data_20241205_120000.csv`.

---

## ğŸ“‚ File Structure
```
web-scraper-with-csv/
â”‚
â”œâ”€â”€ main.py             # ğŸš€ Main script for scraping and exporting
â”œâ”€â”€ requirements.txt    # ğŸ“¦ List of dependencies
â””â”€â”€ README.md           # ğŸ“– Documentation
```

---

## ğŸ¤ Contributions
Contributions are welcome! ğŸ‰ To contribute:
1. ğŸ´ Fork this repository.
2. ğŸ› ï¸ Create a feature branch (`git checkout -b feature-branch-name`).
3. âœï¸ Commit your changes (`git commit -m "Add feature"`).
4. ğŸ”„ Push to the branch (`git push origin feature-branch-name`).
5. ğŸ“© Open a pull request.

---

## ğŸ§‘â€ğŸ’» Author
Developed by **Arpit**.  

ğŸ’Œ Contact me at [bitstoday@gmail.com](mailto:bitstoday@gmail.com) or check out my [GitHub Profile](https://github.com/arktrek).

---

Let me know if you'd like to add any more flair or customizations! ğŸ‰
